num_crawler_processes: 20  # 爬虫进程数量限制
max_wait_time: 10  # 爬取页面时最大等待时间
file_input: "input.txt"  # 输入文件名称
file_output: "output.xlsx"  # 输出文件名称
chrome_driver_path: "/usr/bin/chromedriver"  # ChromeDriver路径

log_file: "logs/run.log"  # 日志文件路径
file_ip_data: "data/china_ip_list.txt"  # 中国大陆境内IP数据文件
ip_data_url: "https://raw.githubusercontent.com/17mon/china_ip_list/master/china_ip_list.txt"  # 中国大陆境内IP数据文件下载地址
keywords_file_file: "data/keywords.txt"  # 用于二次校验的关键词组合
keywords_match_ratio_auxiliary: 0.2  # 关键词匹配率辅助判定阈值
keywords_match_ratio_independent: 0.5 # 关键词匹配独立判定阈值
keywords_similarity_independent: 0.1 # 关键词匹配独立判定与其他文本的相似度阈值
crawler_user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36; Baiduspider/2.0"
